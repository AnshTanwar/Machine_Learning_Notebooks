{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5256b50",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-12T17:31:04.944967Z",
     "iopub.status.busy": "2024-04-12T17:31:04.944612Z",
     "iopub.status.idle": "2024-04-12T17:31:05.700709Z",
     "shell.execute_reply": "2024-04-12T17:31:05.699740Z"
    },
    "papermill": {
     "duration": 0.766158,
     "end_time": "2024-04-12T17:31:05.702884",
     "exception": false,
     "start_time": "2024-04-12T17:31:04.936726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/caltech1/caltech1.csv\n",
      "/kaggle/input/hourly-traffic-combined-caltech/hourly_traffic_caltech1.csv\n",
      "/kaggle/input/merged-caltech-weather-traffic/merged_data_wt2.csv\n",
      "/kaggle/input/merged-caltech-weather-traffic/merged_data_wt.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03b535a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T17:31:05.716034Z",
     "iopub.status.busy": "2024-04-12T17:31:05.715634Z",
     "iopub.status.idle": "2024-04-12T17:31:06.904713Z",
     "shell.execute_reply": "2024-04-12T17:31:06.903780Z"
    },
    "papermill": {
     "duration": 1.198109,
     "end_time": "2024-04-12T17:31:06.907125",
     "exception": false,
     "start_time": "2024-04-12T17:31:05.709016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3dd7511",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T17:31:06.920020Z",
     "iopub.status.busy": "2024-04-12T17:31:06.919646Z",
     "iopub.status.idle": "2024-04-12T17:31:07.731743Z",
     "shell.execute_reply": "2024-04-12T17:31:07.730760Z"
    },
    "papermill": {
     "duration": 0.820793,
     "end_time": "2024-04-12T17:31:07.733875",
     "exception": false,
     "start_time": "2024-04-12T17:31:06.913082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26/1687947547.py:1: DtypeWarning: Columns (3,4,5,6,7,10,11,13,14,15,18,20,39) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/kaggle/input/hourly-traffic-combined-caltech/hourly_traffic_caltech1.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/hourly-traffic-combined-caltech/hourly_traffic_caltech1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c30805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T17:31:07.747281Z",
     "iopub.status.busy": "2024-04-12T17:31:07.746947Z",
     "iopub.status.idle": "2024-04-12T17:31:07.754105Z",
     "shell.execute_reply": "2024-04-12T17:31:07.753223Z"
    },
    "papermill": {
     "duration": 0.016243,
     "end_time": "2024-04-12T17:31:07.756205",
     "exception": false,
     "start_time": "2024-04-12T17:31:07.739962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0', '_id', 'userInputs',\n",
       "       'sessionID', 'stationID', 'spaceID', 'siteID', 'clusterID',\n",
       "       'connectionTime', 'disconnectTime', 'kWhDelivered', 'doneChargingTime',\n",
       "       'timezone', 'userID', 'session_duration', 'Weekend', 'connectionDate',\n",
       "       'clouds', 'datetime', 'dewpt', 'dhi', 'dni', 'ghi', 'max_dhi',\n",
       "       'max_dni', 'max_ghi', 'max_temp', 'max_temp_ts', 'max_uv',\n",
       "       'max_wind_dir', 'max_wind_spd', 'max_wind_spd_ts', 'min_temp',\n",
       "       'min_temp_ts', 'precip', 'precip_gpm', 'pres', 'revision_status', 'rh',\n",
       "       'slp', 'snow', 'snow_depth', 'solar_rad', 't_dhi', 't_dni', 't_ghi',\n",
       "       't_solar_rad', 'temp', 'ts', 'wind_dir', 'wind_gust_spd', 'wind_spd',\n",
       "       'Date', 'Hour', 'TrafficVolume', 'AverageSpeed',\n",
       "       'TrafficVolume_squared', 'AverageSpeed_squared'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0884d403",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T17:31:07.769966Z",
     "iopub.status.busy": "2024-04-12T17:31:07.769509Z",
     "iopub.status.idle": "2024-04-12T17:31:07.837371Z",
     "shell.execute_reply": "2024-04-12T17:31:07.836482Z"
    },
    "papermill": {
     "duration": 0.077263,
     "end_time": "2024-04-12T17:31:07.839744",
     "exception": false,
     "start_time": "2024-04-12T17:31:07.762481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from datetime import datetime\n",
    "\n",
    "# Assuming 'df' is your DataFrame with the Date column\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Day of the Week\n",
    "df['Day_of_Week'] = df['Date'].dt.day_name()\n",
    "\n",
    "# Month\n",
    "df['Month'] = df['Date'].dt.month\n",
    "\n",
    "# Day of the Month\n",
    "df['Day_of_Month'] = df['Date'].dt.day\n",
    "\n",
    "# Public Holidays\n",
    "cal = USFederalHolidayCalendar()\n",
    "holidays = cal.holidays(start=df['Date'].min(), end=df['Date'].max())\n",
    "df['Public_Holiday'] = df['Date'].isin(holidays)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eae7517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T17:31:07.853000Z",
     "iopub.status.busy": "2024-04-12T17:31:07.852695Z",
     "iopub.status.idle": "2024-04-12T17:31:07.871138Z",
     "shell.execute_reply": "2024-04-12T17:31:07.870267Z"
    },
    "papermill": {
     "duration": 0.027185,
     "end_time": "2024-04-12T17:31:07.873153",
     "exception": false,
     "start_time": "2024-04-12T17:31:07.845968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0','sessionID','connectionTime','disconnectTime','doneChargingTime',\n",
    "              'timezone','datetime','connectionDate', 'Date', 'snow', 'snow_depth', 'solar_rad', 't_dhi',\n",
    "       't_dni', 't_ghi', 't_solar_rad','revision_status', 'userID','stationID','spaceID',\n",
    "              'Unnamed: 0.2', 'Unnamed: 0.1', '_id', 'wind_gust_spd', 'wind_spd','userInputs', 'siteID','dhi', 'dni', 'ghi', \n",
    "              'max_dhi', 'max_dni', 'max_ghi','clusterID','TrafficVolume_squared', 'AverageSpeed_squared'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2070c007",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T17:31:07.886507Z",
     "iopub.status.busy": "2024-04-12T17:31:07.886218Z",
     "iopub.status.idle": "2024-04-12T17:31:07.891376Z",
     "shell.execute_reply": "2024-04-12T17:31:07.890547Z"
    },
    "papermill": {
     "duration": 0.014087,
     "end_time": "2024-04-12T17:31:07.893362",
     "exception": false,
     "start_time": "2024-04-12T17:31:07.879275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35551, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d67f663",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T17:31:07.906803Z",
     "iopub.status.busy": "2024-04-12T17:31:07.906535Z",
     "iopub.status.idle": "2024-04-12T17:31:07.912027Z",
     "shell.execute_reply": "2024-04-12T17:31:07.911165Z"
    },
    "papermill": {
     "duration": 0.01458,
     "end_time": "2024-04-12T17:31:07.914020",
     "exception": false,
     "start_time": "2024-04-12T17:31:07.899440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['kWhDelivered', 'session_duration', 'Weekend', 'clouds', 'dewpt',\n",
       "       'max_temp', 'max_temp_ts', 'max_uv', 'max_wind_dir', 'max_wind_spd',\n",
       "       'max_wind_spd_ts', 'min_temp', 'min_temp_ts', 'precip', 'precip_gpm',\n",
       "       'pres', 'rh', 'slp', 'temp', 'ts', 'wind_dir', 'Hour', 'TrafficVolume',\n",
       "       'AverageSpeed', 'Day_of_Week', 'Month', 'Day_of_Month',\n",
       "       'Public_Holiday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93accbf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T17:31:07.927853Z",
     "iopub.status.busy": "2024-04-12T17:31:07.927100Z",
     "iopub.status.idle": "2024-04-12T17:31:07.958716Z",
     "shell.execute_reply": "2024-04-12T17:31:07.957749Z"
    },
    "papermill": {
     "duration": 0.04056,
     "end_time": "2024-04-12T17:31:07.960727",
     "exception": false,
     "start_time": "2024-04-12T17:31:07.920167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kWhDelivered</th>\n",
       "      <th>session_duration</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>clouds</th>\n",
       "      <th>dewpt</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>max_temp_ts</th>\n",
       "      <th>max_uv</th>\n",
       "      <th>max_wind_dir</th>\n",
       "      <th>max_wind_spd</th>\n",
       "      <th>...</th>\n",
       "      <th>temp</th>\n",
       "      <th>ts</th>\n",
       "      <th>wind_dir</th>\n",
       "      <th>Hour</th>\n",
       "      <th>TrafficVolume</th>\n",
       "      <th>AverageSpeed</th>\n",
       "      <th>Day_of_Week</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day_of_Month</th>\n",
       "      <th>Public_Holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.932</td>\n",
       "      <td>132.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>1.524697e+09</td>\n",
       "      <td>10.1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.6</td>\n",
       "      <td>1.524640e+09</td>\n",
       "      <td>163.0</td>\n",
       "      <td>11</td>\n",
       "      <td>207.866567</td>\n",
       "      <td>30.635825</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.013</td>\n",
       "      <td>671.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>1.524697e+09</td>\n",
       "      <td>10.1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.6</td>\n",
       "      <td>1.524640e+09</td>\n",
       "      <td>163.0</td>\n",
       "      <td>13</td>\n",
       "      <td>225.258907</td>\n",
       "      <td>30.146676</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.257</td>\n",
       "      <td>558.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>1.524697e+09</td>\n",
       "      <td>10.1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.6</td>\n",
       "      <td>1.524640e+09</td>\n",
       "      <td>163.0</td>\n",
       "      <td>13</td>\n",
       "      <td>225.258907</td>\n",
       "      <td>30.146676</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.177</td>\n",
       "      <td>558.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>1.524697e+09</td>\n",
       "      <td>10.1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.6</td>\n",
       "      <td>1.524640e+09</td>\n",
       "      <td>163.0</td>\n",
       "      <td>14</td>\n",
       "      <td>221.778145</td>\n",
       "      <td>30.358765</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.119</td>\n",
       "      <td>502.633333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>1.524697e+09</td>\n",
       "      <td>10.1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.6</td>\n",
       "      <td>1.524640e+09</td>\n",
       "      <td>163.0</td>\n",
       "      <td>14</td>\n",
       "      <td>221.778145</td>\n",
       "      <td>30.358765</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   kWhDelivered  session_duration  Weekend  clouds  dewpt  max_temp  \\\n",
       "0         7.932        132.100000      0.0    21.0    1.7      24.4   \n",
       "1        10.013        671.100000      0.0    21.0    1.7      24.4   \n",
       "2         5.257        558.916667      0.0    21.0    1.7      24.4   \n",
       "3         5.177        558.466667      0.0    21.0    1.7      24.4   \n",
       "4        10.119        502.633333      0.0    21.0    1.7      24.4   \n",
       "\n",
       "    max_temp_ts  max_uv  max_wind_dir  max_wind_spd  ...  temp            ts  \\\n",
       "0  1.524697e+09    10.1         163.0           3.0  ...  17.6  1.524640e+09   \n",
       "1  1.524697e+09    10.1         163.0           3.0  ...  17.6  1.524640e+09   \n",
       "2  1.524697e+09    10.1         163.0           3.0  ...  17.6  1.524640e+09   \n",
       "3  1.524697e+09    10.1         163.0           3.0  ...  17.6  1.524640e+09   \n",
       "4  1.524697e+09    10.1         163.0           3.0  ...  17.6  1.524640e+09   \n",
       "\n",
       "   wind_dir  Hour  TrafficVolume  AverageSpeed  Day_of_Week  Month  \\\n",
       "0     163.0    11     207.866567     30.635825    Wednesday      4   \n",
       "1     163.0    13     225.258907     30.146676    Wednesday      4   \n",
       "2     163.0    13     225.258907     30.146676    Wednesday      4   \n",
       "3     163.0    14     221.778145     30.358765    Wednesday      4   \n",
       "4     163.0    14     221.778145     30.358765    Wednesday      4   \n",
       "\n",
       "   Day_of_Month  Public_Holiday  \n",
       "0            25           False  \n",
       "1            25           False  \n",
       "2            25           False  \n",
       "3            25           False  \n",
       "4            25           False  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54ef9195",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T17:31:07.976907Z",
     "iopub.status.busy": "2024-04-12T17:31:07.976632Z",
     "iopub.status.idle": "2024-04-12T17:31:07.980630Z",
     "shell.execute_reply": "2024-04-12T17:31:07.979797Z"
    },
    "papermill": {
     "duration": 0.014142,
     "end_time": "2024-04-12T17:31:07.982598",
     "exception": false,
     "start_time": "2024-04-12T17:31:07.968456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "236a0aed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T17:31:07.997675Z",
     "iopub.status.busy": "2024-04-12T17:31:07.997343Z",
     "iopub.status.idle": "2024-04-12T17:31:08.025277Z",
     "shell.execute_reply": "2024-04-12T17:31:08.024462Z"
    },
    "papermill": {
     "duration": 0.037668,
     "end_time": "2024-04-12T17:31:08.027267",
     "exception": false,
     "start_time": "2024-04-12T17:31:07.989599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in Day_of_Week: ['Wednesday' 'Thursday' 'Friday' 'Saturday' 'Sunday' 'Monday' 'Tuesday']\n",
      "Categorical Columns: ['Weekend', 'Day_of_Week', 'Public_Holiday']\n",
      "Non-Categorical Columns: ['kWhDelivered', 'session_duration', 'clouds', 'dewpt', 'max_temp', 'max_temp_ts', 'max_uv', 'max_wind_dir', 'max_wind_spd', 'max_wind_spd_ts', 'min_temp', 'min_temp_ts', 'precip', 'precip_gpm', 'pres', 'rh', 'slp', 'temp', 'ts', 'wind_dir', 'Hour', 'TrafficVolume', 'AverageSpeed', 'Month', 'Day_of_Month']\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical columns based on data types\n",
    "data_types = data.dtypes\n",
    "categorical_columns = data_types[data_types == 'object'].index.tolist()\n",
    "\n",
    "# Check unique values in categorical columns to confirm if they are indeed categorical\n",
    "for column in categorical_columns:\n",
    "    unique_values = data[column].unique()\n",
    "    print(f\"Unique values in {column}: {unique_values}\")\n",
    "\n",
    "# You can also set a threshold to determine if a column is categorical based on the number of unique values\n",
    "threshold_unique_values = 10  # Adjust threshold as needed\n",
    "categorical_columns = [column for column in data.columns if len(data[column].unique()) <= threshold_unique_values]\n",
    "\n",
    "# Print the identified categorical columns\n",
    "print(\"Categorical Columns:\", categorical_columns)\n",
    "\n",
    "# Non-categorical columns\n",
    "non_categorical_columns = [column for column in data.columns if column not in categorical_columns]\n",
    "print(\"Non-Categorical Columns:\", non_categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71bd91d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T17:31:08.042859Z",
     "iopub.status.busy": "2024-04-12T17:31:08.042539Z",
     "iopub.status.idle": "2024-04-12T17:31:08.079608Z",
     "shell.execute_reply": "2024-04-12T17:31:08.078464Z"
    },
    "papermill": {
     "duration": 0.047731,
     "end_time": "2024-04-12T17:31:08.082213",
     "exception": false,
     "start_time": "2024-04-12T17:31:08.034482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'data' is your DataFrame\n",
    "# List of categorical columns\n",
    "categorical_columns = ['Weekend', 'Day_of_Week', 'Month', 'Public_Holiday']\n",
    "\n",
    "# Apply one-hot encoding for each categorical column\n",
    "for column in categorical_columns:\n",
    "    # Convert the column to one-hot encoded representation\n",
    "    one_hot_encoded = pd.get_dummies(data[column], prefix=column)\n",
    "    # Concatenate the one-hot encoded columns to the original dataframe\n",
    "    data = pd.concat([data, one_hot_encoded], axis=1)\n",
    "    # Drop the original categorical column from the dataframe\n",
    "    data.drop(column, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad65afc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T17:31:08.098474Z",
     "iopub.status.busy": "2024-04-12T17:31:08.098157Z",
     "iopub.status.idle": "2024-04-12T17:31:09.308653Z",
     "shell.execute_reply": "2024-04-12T17:31:09.306309Z"
    },
    "papermill": {
     "duration": 1.229489,
     "end_time": "2024-04-12T17:31:09.319458",
     "exception": false,
     "start_time": "2024-04-12T17:31:08.089969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "   \n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data_imputed = imputer.fit_transform(data)\n",
    "data_imputed = pd.DataFrame(data_imputed, columns=data.columns)\n",
    "\n",
    "data_imputed = data_imputed.drop(['session_duration'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_imputed)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=15)  \n",
    "data_pca = pca.fit_transform(data_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab9739f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T17:31:09.382806Z",
     "iopub.status.busy": "2024-04-12T17:31:09.381950Z",
     "iopub.status.idle": "2024-04-12T17:31:09.943508Z",
     "shell.execute_reply": "2024-04-12T17:31:09.942157Z"
    },
    "papermill": {
     "duration": 0.594649,
     "end_time": "2024-04-12T17:31:09.947269",
     "exception": false,
     "start_time": "2024-04-12T17:31:09.352620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assuming 'data' contains your dataset\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# Drop target variable before PCA\n",
    "X = data_imputed.drop(['session_duration'], axis=1)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=10)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Define target variable\n",
    "y = data_imputed['session_duration']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4871d6c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T17:31:10.011441Z",
     "iopub.status.busy": "2024-04-12T17:31:10.010249Z",
     "iopub.status.idle": "2024-04-12T17:31:10.016290Z",
     "shell.execute_reply": "2024-04-12T17:31:10.014893Z"
    },
    "papermill": {
     "duration": 0.04403,
     "end_time": "2024-04-12T17:31:10.019395",
     "exception": false,
     "start_time": "2024-04-12T17:31:09.975365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #X = data.drop(columns=['session_duration'])\n",
    "# X = data_pca\n",
    "# y = data['session_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c19b067",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T17:31:10.033946Z",
     "iopub.status.busy": "2024-04-12T17:31:10.033706Z",
     "iopub.status.idle": "2024-04-12T17:33:05.775806Z",
     "shell.execute_reply": "2024-04-12T17:33:05.774816Z"
    },
    "papermill": {
     "duration": 115.758787,
     "end_time": "2024-04-12T17:33:05.785210",
     "exception": false,
     "start_time": "2024-04-12T17:31:10.026423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 28440, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 298.162548\n",
      "Random Forest Metrics:\n",
      "RMSE: 369.69038125202127\n",
      "MAE: 163.98784521594087\n",
      "\n",
      "XGBoost Metrics:\n",
      "RMSE: 366.4532080400216\n",
      "MAE: 162.83821011755063\n",
      "\n",
      "LightGBM Metrics:\n",
      "RMSE: 358.9031821434097\n",
      "MAE: 159.7919895446795\n",
      "\n",
      "SVM Metrics:\n",
      "RMSE: 371.4434322787008\n",
      "MAE: 159.50127381049194\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.svm import SVR\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "# Machine Learning Model - Random Forest\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_score = rf_model.score(X_test, y_test)\n",
    "\n",
    "# Machine Learning Model - XGBoost\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_score = xgb_model.score(X_test, y_test)\n",
    "\n",
    "# Machine Learning Model - LightGBM\n",
    "lgbm_model = LGBMRegressor()\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "lgbm_score = lgbm_model.score(X_test, y_test)\n",
    "\n",
    "# Machine Learning Model - SVM\n",
    "svm_model = SVR()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_score = svm_model.score(X_test, y_test)\n",
    "\n",
    "\n",
    "# Predictions\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "lgbm_predictions = lgbm_model.predict(X_test)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate RMSE and MAE for Random Forest\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_predictions))\n",
    "rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
    "\n",
    "# Calculate RMSE and MAE for XGBoost\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_predictions))\n",
    "xgb_mae = mean_absolute_error(y_test, xgb_predictions)\n",
    "\n",
    "# Calculate RMSE and MAE for LightGBM\n",
    "lgbm_rmse = np.sqrt(mean_squared_error(y_test, lgbm_predictions))\n",
    "lgbm_mae = mean_absolute_error(y_test, lgbm_predictions)\n",
    "\n",
    "# Calculate RMSE and MAE for SVM\n",
    "svm_rmse = np.sqrt(mean_squared_error(y_test, svm_predictions))\n",
    "svm_mae = mean_absolute_error(y_test, svm_predictions)\n",
    "\n",
    "\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"RMSE:\", rf_rmse)\n",
    "print(\"MAE:\", rf_mae)\n",
    "print(\"\\nXGBoost Metrics:\")\n",
    "print(\"RMSE:\", xgb_rmse)\n",
    "print(\"MAE:\", xgb_mae)\n",
    "print(\"\\nLightGBM Metrics:\")\n",
    "print(\"RMSE:\", lgbm_rmse)\n",
    "print(\"MAE:\", lgbm_mae)\n",
    "print(\"\\nSVM Metrics:\")\n",
    "print(\"RMSE:\", svm_rmse)\n",
    "print(\"MAE:\", svm_mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dddad1",
   "metadata": {
    "papermill": {
     "duration": 0.00689,
     "end_time": "2024-04-12T17:33:05.799363",
     "exception": false,
     "start_time": "2024-04-12T17:33:05.792473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09466215",
   "metadata": {
    "papermill": {
     "duration": 0.006624,
     "end_time": "2024-04-12T17:33:05.812846",
     "exception": false,
     "start_time": "2024-04-12T17:33:05.806222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ae8cc1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-12T17:33:05.828371Z",
     "iopub.status.busy": "2024-04-12T17:33:05.828065Z",
     "iopub.status.idle": "2024-04-12T17:33:05.833311Z",
     "shell.execute_reply": "2024-04-12T17:33:05.832457Z"
    },
    "papermill": {
     "duration": 0.015375,
     "end_time": "2024-04-12T17:33:05.835240",
     "exception": false,
     "start_time": "2024-04-12T17:33:05.819865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Feature Selection\n",
    "# model = RandomForestRegressor()\n",
    "# model.fit(data_pca, data_imputed['session_duration'])  # Replace 'target_column' with your target variable\n",
    "# feature_importances = model.feature_importances_\n",
    "# selector = SelectFromModel(model, prefit=True)\n",
    "# selected_features = selector.transform(data_imputeda)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(selected_features, data_imputed['session_duration'], test_size=0.2)\n",
    "\n",
    "# # Machine Learning Model - Random Forest\n",
    "# rf_model = RandomForestRegressor()\n",
    "# rf_model.fit(X_train, y_train)\n",
    "# rf_score = rf_model.score(X_test, y_test)\n",
    "\n",
    "# # Machine Learning Model - XGBoost\n",
    "# xgb_model = XGBRegressor()\n",
    "# xgb_model.fit(X_train, y_train)\n",
    "# xgb_score = xgb_model.score(X_test, y_test)\n",
    "\n",
    "# # print(\"Random Forest Score:\", rf_score)\n",
    "# # print(\"XGBoost Score:\", xgb_score)\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# import numpy as np\n",
    "\n",
    "# # Predictions\n",
    "# rf_predictions = rf_model.predict(X_test)\n",
    "# xgb_predictions = xgb_model.predict(X_test)\n",
    "\n",
    "# # Calculate RMSE and MAE for Random Forest\n",
    "# rf_rmse = np.sqrt(mean_squared_error(y_test, rf_predictions))\n",
    "# rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
    "\n",
    "# # Calculate RMSE and MAE for XGBoost\n",
    "# xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_predictions))\n",
    "# xgb_mae = mean_absolute_error(y_test, xgb_predictions)\n",
    "\n",
    "# # Print the evaluation metrics\n",
    "# print(\"Random Forest Metrics:\")\n",
    "# print(\"RMSE:\", rf_rmse)\n",
    "# print(\"MAE:\", rf_mae)\n",
    "# print(\"\\nXGBoost Metrics:\")\n",
    "# print(\"RMSE:\", xgb_rmse)\n",
    "# print(\"MAE:\", xgb_mae)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4696377,
     "sourceId": 7979644,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4779117,
     "sourceId": 8100492,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4784929,
     "sourceId": 8102191,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 124.395332,
   "end_time": "2024-04-12T17:33:06.562166",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-12T17:31:02.166834",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
